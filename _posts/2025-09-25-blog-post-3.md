---
title: 'Blog 3: Exception to Data Driven Rules'
date: 2025-09-25
permalink: /posts/2025/09/blog-post-3/
tags:
 - case study
 - ethics
---


Towards equitable exceptions


A data-driven rule is an algorithm that guides decision making, for example in hiring and healthcare to credit scoring and parole. The case study argues that when algorithms are used for decisions, individuals have a right to be an exception to data-driven rule. It proposes a way of evaluating the propriety of an algorithmic recommendation on an individual. 

An exception to a data-driven rule is an individual unit (person or otherwise) applying the algorithm to is inappropriate. Data-driven rules can be used in contexts in which they are not useful. For example, while working with job seekers without college education, I noticed that systems failed to recognise the value of their nontraditional experience. Despite their beyond adequate qualifications and work ethic, applicant tracking systems automatically rejected them.

While there dangers to data-driven rules, there are benefits. Data-driven rule is useful when patterns genuinely help us make informed decisions—like using population data to prescribe ibuprofen for fever. But when algorithms dictate outcomes in areas shaped by culture, language, or unequal access like employment or education, they risk amplifying exclusion. Not every human story fits a data pattern.

There are great benefits for individualisation.  It protects people with non-standard profiles, like the elderly and migrants, who are usually outside of the intended user profile and who may be experiencing language barriers in addition to tech illiteracy. Granting exceptions introduces human bias, and excessive scrutiny could become invasive or paternalistic. Still, I think this trade-off is preferrable to the ostensible objectivity of models. At some point a human must make a decision, therefore to center uncertainty is to ensure accountability.

Uncertainty is a helpful critical tool. It is the degree to which the model cannot ascertain a decision with appropriate confidence. To center uncertainty is to foreground the simple truth that all models are wrong, and the eventually, a human actor must face the ethical decision of accepting or rejecting a unit with evalutating the consequences of their actions.

In conclusion, I think that applying data-driven rule could be best used in cases where human bias poses a greater risk than machine bias, like in cancer diagnostics or air traffic control. However, in contexts where identity and lived experience matter, like hiring and criminal sentencing, humans should maintain the authority to decide.

When data-driven rules fail to recognize human diversity, who should have the power to grant exceptions? 

I chose this question because it shifts the debate from whether exceptions should exist to who decides when they are justified. The algorithm’s designer could integrate this difference back into the model, the institution using it can audit past decisions to remedy them, and the affected individual can receive their "right" outcome.

This was a helpful article to think about algorithmic fairness. Using models to influence people’s lives can be a double edged sword. Careful evaluation frameworks and critical thought must accompany any effort of this nature.
