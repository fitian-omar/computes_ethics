---
permalink: /casestudy/
title: "Case Study: Normative Discourse of AI"
author_profile: true
---

# Learning Objectives
- Explain how normative discourse operates within Large Language Models (LLMs).
- Reflect on the dialectic of society and AI.
- Identify how moral and epistemic biases are embedded in LLMs.
- Evaluate the effects of these biases on different stakeholders.


# Introduction

Large Language Models (LLMs) such as GPT, Claude, and Gemini are now integral to global knowledge production. They generate text, summarise ideas, and make moral judgements. While portrayed as objective and value-free, they are not. This case study analyses how these models shape and enforce normative discourses. A normative discourse is a set of moral, cultural, and epsitemological assumptions about what coutns as truth, fairness, or reason that is structured through both language, power, and knowledge. Let's explore the ethical implications of these discourses from empirical and theoretical work to understand how LLMs encode moral norms, enact power through knoelwedge, and shape the boundaries of acceptable knowledge.



# The Issue
LLMs are not value-free. Agbon (2024) argues that generative AI operates through a dual discourse:
1. Technoslutionst discourse: frames AI as a benevolent problem-solver.
2. Generative discourse: the machine's language as shaped by its training data, architecture, and algorithms.

Together, these discourses reproduce existing power relations by privileging certain epistemologies, Western, Anglophone, liberal, while magrginalising others. This can harm groups whose moral frameworks differ from dominant ones, particularly when AI becomes an authority that adjudicates truth, fairness, and decency in online and institutional spaces.

Discuss the Am I The Asshole paper

Other instances of discourse harming people

# What We Know

Discuss how AI works and how it relates to our study, as well as what we are yet to understand about AI

# Stakeholders

- Gen AI Users
- Developers
- Marginalised communities
- Policymakers
- Researchers

# Activity

Users will answer receive Am I The Asshole prompts and answer them. Each answer will explain the harm in taking a moral stance, compare to the answers of models, understand why the models differ.

[Activity](_casestudy/activity)

# Actions

Lists possible actions, implementation steps, and evaluates them through our six ethical frameworks

# Conclusion

Will choose the best option, flesh out its implementation. Reflect on exercise

# Discussion Questions

1. How do the dual discourses shape the way we perceive LLMs?
2. Is algorithmic neutrality impossible achievable?
3. How can algorithmic control balance protecting users and allowing for moral pluralism?

# Works Cited

Agbon, G. (2024). Who speaks through the machine? Generative AI as discourse and implications for management. Critical Perspectives on Accounting, 100, 102761. https://doi.org/10.1016/j.cpa.2024.102761
   
Gillings, M., Kohn, T., & Mautner, G. (2024). The rise of large language models: challenges for Critical Discourse Studies. Critical Discourse Studies, 22(6), 625â€“641. https://doi.org/10.1080/17405904.2024.2373733

Sachdeva, Pratik, and Tom van Nuenen. "Normative evaluation of large language models with everyday moral dilemmas." Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency. 2025.